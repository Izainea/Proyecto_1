{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eficiencia de un cluster\n",
    "Para evaluar la eficiencia de un cluster en el contexto de un modelo de aprendizaje automático no supervisado, se utilizan métodos que intentan cuantificar qué tan bien el modelo ha agrupado los datos. A diferencia del aprendizaje supervisado, no tenemos etiquetas verdaderas para comparar, por lo que debemos basarnos en métricas intrínsecas que miden la calidad de los clusters formados. Aquí hay algunas métricas comúnmente utilizadas para este propósito:\n",
    "\n",
    "1. **Coeficiente de Silueta**:\n",
    "   - Mide cómo de similar es un objeto a su propio cluster comparado con otros clusters. El coeficiente puede variar de -1 a 1, donde un valor alto indica que el objeto está bien emparejado con su propio cluster y mal emparejado con los vecinos.\n",
    "\n",
    "2. **Índice Davies-Bouldin**:\n",
    "   - Es una métrica basada en la relación entre la dispersión dentro de los clusters y la separación entre ellos. Un índice Davies-Bouldin más bajo indica una mejor partición.\n",
    "\n",
    "3. **Calinski-Harabasz Index** (Índice de la varianza entre grupos sobre la varianza dentro del grupo):\n",
    "   - Es alto cuando los clusters son densos y bien separados, lo cual se relaciona con un modelo de clustering más efectivo.\n",
    "\n",
    "4. **Dunn Index**:\n",
    "   - Mide la relación entre las distancias mínimas interclusters y las máximas distancias intracluster. Un valor mayor indica una mejor separación de los clusters.\n",
    "\n",
    "Para aplicar estas métricas, primero necesitas tener un modelo de clustering entrenado, como K-Means, DBSCAN, o cualquier otro algoritmo de clustering. Luego, usando las etiquetas de cluster asignadas por el modelo a tus datos, calculas las métricas para evaluar la calidad del clustering. \n",
    "\n",
    "Es importante recordar que ninguna métrica es perfecta y cada una tiene sus propias ventajas y limitaciones. A menudo, la mejor práctica es utilizar varias métricas en conjunto para obtener una visión más completa de la eficacia del modelo de clustering. Además, la interpretación de estas métricas debe hacerse en el contexto de tu problema específico y los datos con los que estás trabajando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matemática detrás de las métricas\n",
    "\n",
    "Vamos a explorar la matemática detrás de las métricas comunes de evaluación de clustering mencionadas, proporcionando una comprensión básica de cómo se calculan y qué representan.\n",
    "\n",
    "### 1. Coeficiente de Silueta\n",
    "\n",
    "El Coeficiente de Silueta mide cuán similar es un punto a su propio cluster comparado con otros clusters. Para un punto \\(i\\), el coeficiente se calcula como sigue:\n",
    "\n",
    "$$ s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}} $$\n",
    "\n",
    "donde:\n",
    "- $\\(a(i)\\)$ es la distancia media entre \\(i\\) y todos los otros puntos en el mismo cluster.\n",
    "- \\(b(i)\\) es la menor distancia media de \\(i\\) a todos los puntos en cualquier otro cluster, de los cuales \\(i\\) no es miembro.\n",
    "\n",
    "El valor de \\(s(i)\\) está entre -1 y 1, donde un valor alto indica que el punto está bien emplazado en su cluster.\n",
    "\n",
    "### 2. Índice Davies-Bouldin\n",
    "\n",
    "El Índice Davies-Bouldin es una función de la relación entre la dispersión dentro del cluster y la separación entre clusters. Para \\(k\\) clusters, el índice se define como:\n",
    "\n",
    "$$DB = \\frac{1}{k} \\sum_{i=1}^{k} \\max_{j \\neq i} \\left( \\frac{\\sigma_i + \\sigma_j}{d(c_i, c_j)} \\right) $$\n",
    "\n",
    "donde:\n",
    "- \\(k\\) es el número de clusters,\n",
    "- \\($\\sigma_i$\\) es la dispersión media dentro del cluster \\(i\\),\n",
    "- \\(d(c_i, c_j)\\) es la distancia entre los centroides de los clusters \\(i\\) y \\(j\\).\n",
    "\n",
    "Un valor más bajo indica una mejor separación de clusters.\n",
    "\n",
    "\n",
    "### 3. Índice Calinski-Harabasz\n",
    "\n",
    "El Índice Calinski-Harabasz, también conocido como el criterio del ratio de la varianza, se calcula como sigue:\n",
    "\n",
    "$$ CH = \\frac{B(k) / (k - 1)}{W(k) / (N - k)} $$\n",
    "\n",
    "donde:\n",
    "- \\(N\\) es el número total de puntos,\n",
    "- \\(k\\) es el número de clusters,\n",
    "- \\(B(k)\\) es la suma de cuadrados entre grupos (varianza entre los clusters),\n",
    "- \\(W(k)\\) es la suma de cuadrados dentro del grupo (varianza dentro de los clusters).\n",
    "\n",
    "Un valor más alto sugiere clusters más definidos.\n",
    "\n",
    "### 4. Índice Dunn\n",
    "\n",
    "El Índice Dunn mide la relación entre la menor distancia entre observaciones de diferentes clusters y la mayor distancia entre observaciones dentro de un cluster:\n",
    "\n",
    "$$ D = \\min_{1 \\leq i < j \\leq k} \\left( \\frac{\\delta(c_i, c_j)}{\\max_{1 \\leq l \\leq k} \\Delta(c_l)} \\right) $$\n",
    "\n",
    "donde:\n",
    "- \\($\\delta$(c_i, c_j)\\) es la distancia entre clusters \\(i\\) y \\(j\\),\n",
    "- \\($\\Delta(c_l)$\\) es la distancia intracluster máxima para el cluster \\(l\\).\n",
    "\n",
    "Un valor más alto indica una mejor separación de clusters.\n",
    "\n",
    "Cada una de estas métricas ofrece una perspectiva diferente sobre la calidad de los clusters formados por un algoritmo de clustering. La elección de qué métricas usar puede depender del contexto específico del problema y de las características de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La intuición detrás de cada una de estas métricas de evaluación de clustering ayuda a comprender qué aspectos de la agrupación están midiendo y cómo interpretar sus resultados en términos prácticos. A continuación, se detalla la intuición principal detrás de cada métrica mencionada:\n",
    "\n",
    "### 1. Coeficiente de Silueta\n",
    "\n",
    "- **Intuición**: Mide cuán cerca está cada punto de los puntos de su propio cluster en comparación con los puntos del cluster más cercano. Un coeficiente de silueta alto sugiere que el punto está bien situado en su cluster y lejos de los clusters vecinos. Es útil para identificar si los puntos han sido asignados al cluster correcto y cuán definidos están los límites entre clusters.\n",
    "\n",
    "### 2. Índice Davies-Bouldin\n",
    "\n",
    "- **Intuición**: Evalúa la compactación y la separación de los clusters. Busca clusters donde los puntos estén lo más cerca posible unos de otros (alta densidad interna) y lo más lejos posible de puntos en otros clusters (buena separación). Un índice bajo indica que los clusters están densamente agrupados internamente y bien separados entre sí.\n",
    "\n",
    "### 3. Índice Calinski-Harabasz\n",
    "\n",
    "- **Intuición**: Compara la dispersión entre clusters con la dispersión dentro de los clusters. Prefiere clusters que son muy diferentes entre sí (alta varianza entre clusters) pero que tienen puntos muy similares dentro de ellos (baja varianza dentro de los clusters). Un valor alto sugiere que los clusters son bien definidos y separados.\n",
    "\n",
    "### 4. Índice Dunn\n",
    "\n",
    "- **Intuición**: Se centra en la distancia mínima entre los clusters y la distancia máxima dentro de los clusters para evaluar la separación y la compactación. Un valor alto indica que el cluster más cercano está lejos comparado con el tamaño del cluster más grande, lo cual es deseable. Es especialmente útil para identificar configuraciones de clustering donde los clusters están bien separados y son compactos.\n",
    "\n",
    "Cada una de estas métricas ofrece un enfoque diferente para evaluar la calidad de un conjunto de clusters. Algunas se centran más en la separación entre clusters, otras en la cohesión interna, y algunas intentan equilibrar ambos aspectos. La elección de la métrica adecuada depende del objetivo específico del análisis de clustering y de las características inherentes a los datos que se están analizando. En la práctica, es común utilizar varias métricas en conjunto para obtener una visión completa de la calidad del clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
